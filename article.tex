\documentclass[fleqn,10pt]{SelfArx} % Document font size and equations flushed left

\usepackage{float}
\usepackage{mdwlist}
\usepackage{caption}
\usepackage{hyperref}
\usepackage{verbatim}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{listings}

% Consider inserting:
%\usepackage{kpfonts}

\setlength{\columnsep}{0.55cm} % Distance between the two columns of text
\setlength{\fboxrule}{0.75pt} % Width of the border around the abstract

\definecolor{color1}{RGB}{0,0,0} % Color of the article title and sections
\definecolor{color2}{RGB}{0,20,20} % Color of the boxes behind the abstract and headings

\newlength{\tocsep} 
\setlength\tocsep{1.5pc} % Sets the indentation of the sections in the table of contents
\setcounter{tocdepth}{3} % Show only three levels in the table of contents section: sections, subsections and subsubsections

\lstset { 
	language=C,
	tabsize=2,
	backgroundcolor=\color{black!5},
	basicstyle=\footnotesize,
}

\JournalInfo{\today} % Journal information
\Archive{Unpublished} % Additional notes (e.g. copyright, DOI, review/research article)
\PaperTitle{Emulated~GPGPU~Kernels\\A~Study~into~Performance} % Article title
\Authors{Eric~Nilsson} % Authors
\affiliation{EricNNilsson@gmail.com}
%\affiliation{*\textit{Corresponding author}: john@smith.com} % Corresponding author
\Keywords{GPGPU, GPU,  Simulation, Emulation, DirectCompute, WARP} % Keywords - if you don't want any simply remove all the text between the curly brackets
\newcommand{\keywordname}{Keywords} % Defines the keywords heading name

% ABSTRACT
\Abstract{
\ldots \\
As such, the hypothesis suggested in this proposal may be summarized as follows:
\quote{\textit{The performance of an emulated GPGPU-kernel on a CPU may have it’s performance substantially improved in exchange for some computational precision.}}
% Background	(what)
%	Vilket sammanhang utgör studiens bakgrund?
% Challenge		(why)
%	Vilka utmaningar omfattar studien?
% Approach		(how)
%	Vilken ansats tillämpas i studien?
% Results 		(what)
%	Vilka resultat gav studien?
}

\begin{document}
\flushbottom % Makes all text pages the same height
\maketitle % Print the title and abstract box
\thispagestyle{empty} % Removes page numbering from the first page

% INTRODUCTION
\section*{Introduction} % The \section*{} command stops section numbering
\addcontentsline{toc}{section}{\hspace*{-\tocsep}Introduction} % Adds this section to the table of contents with negative horizontal space equal to the indent for the numbered sections
\label{sec:introduction}
% Background and Challenge
%	Vilket sammanhang utgör studiens bakgrund?
%	Vilka utmaningar omfattar studien?
When developing \textit{GPU}-kernels relatively small changes may induce large deviations in performance, due to massively parallelized instruction sets and architectural differences in-
between on-chip hardware. Therefore, it may be desirable for the developer to be able to view the data he or she is modifying on the graphics card - a possibility often limited in terms of \textit{GPGPU}-
technologies.\\
% Approach and Result
%	Vilken ansats tillämpas i studien?
The increased utilization of \textit{GPGPU} has brought forth the need of more extensive debugging-possibilities involving access of data that may be hard to retrieve from the hardware - possibly due to architectural differences in-between chip manufacturers. A preferred solution to this problem has been to emulate such \textit{GPU}-kernels on the \textit{CPU} - in exchange for substantial performance-losses. Other resons to emulate \textit{GPU}-kernels may concern pre-silicon development - that is, development for hardware not yet existant, when hardware is busy, or otherwize unavailable. This study comprises an investigation into the performance of software emulation of hardware accelerated \textit{GPGPU}-kernels, by the means of analyzing several software rasterizers.\\
\\
Furthermore, this study concerns inquiry into the \textit{DirectCompute}-framework on the \textit{Windows}-platform, analyzing the performance of a \textit{GPGPU}-kernel on-chip, using the \textit{DirectX} standard software rasterizer, and utilizing the \textit{DirectX~11.1}-addition Microsoft~\textit{WARP}\footnote{\textit{Windows~Advanced~Rasterization~Platform}.}-technology - which promises high-speed software emulation in exchange for some computational precision\footnote{See Microsoft's \textit{WARP~Guide}: \url{http://bit.ly/19hiwrZ}}. \\
%	Vilka resultat gav studien?
%\\
%This study concludes that the performance loss of emulated \textit{GPGPU}-kernel may be considered negligible in exchange for possible extended possibilities of data extraction and increased granularity. As such, Microsoft~\textit{WARP}-technology may be considered feasible for use in industry rasterization\footnote{Such a use-case might be if hardware is unavailable, not suffiecient or busy - as suggested by Microsoft. Link to Microsofts page on WARP here!}.\\
\\
% Outline and Conclusion
As such, the study concerns the fields of simulation, emulation and \textit{GPU}-technologies - respectively, with the purpose of facilitating debugging and profiling of \textit{GPU}-kernels, whilst maintaining acceptable performance.
%	Vilket upplägg har resterande delar av matrialet?

% CONTRIBUTION
\section{Contribution}
\label{sec:contribution}
% Introduction
%	Vilka principer, modeller, metoder och teknologier omfattar studiens design?

% CONTRIBUTION - METHOD
\subsection{Object~of~Study}
\label{sec:contribution:objectofstudy}
Considering possible precision loss caused by \textit{WARP}, it is important that the object~of~study is measurable and deterministic. For the purpose of this experiment, the data computed corresponds to a square matrix~multiplication of dimension $200x200$\footnote{Why 200x200?}. The result of such an operation can easily be verified as correct, and potential losses in computational precision may be computed from the expected data-type. This operation was therefore considered suitable for the purpose of the experiment.\\
Throughout this material, the compiled data will thusly be referred to as $AB=C$.

\subsection{Method}
\label{sec:contribution:method}
In order to establish the object~of~study $AB=C$, the experiment utilizes \textit{GPU}-kernels using which the result is calculated, in it’s entirety, in aforementioned kernel on some target platform. The experiment is devised of the following approximate steps in order to compile the object~of~study $AB=C$:
\begin{enumerate*}
	\item Randomize two matrices $A$ \& $B$ using desired data-type.
	\item Establish the product-matrix $AB=Ref$. The resulting matrix will be used as a reference matrix to verify the final result.
	\item Start a synchronized high-precision timer.
	\item Dispatch \textit{GPU}-kernel calculating the product matrix $AB=C$.
	\item Stop the timer once the kernel has finished execution.
	\item Establish possible deviation in-between resulting matrix $C$ and the previously established matrix $Ref$.
\end{enumerate*}

\subsection{Subjects~of~Study}
\label{sec:contribution:subjectofstudy}
% Describe these modes and what they entail:
The \textit{GPU}-kernels described in Section~\ref{sec:contribution:method} are comprised of \textit{HLSL}-syntax and are compiled \& executed using Microsoft~\textit{DirectCompute}. These kernels are run using three types of hardware~acceleration with varying strategies of \textit{GPU}-kernel emulation. These are comprised of the following:
\paragraph{Hardware-Acceleration~(GPU)}
	The execution of a \textit{DirectCompute}-kernel on a graphics card. Thus, this case will act as a reference for the emulated subjects.\\
	Expected high performance.
\paragraph{Software~Rasterization~(CPU)}
	The emulated execution of a \textit{DirectCompute}-kernel using the \textit{DirectX}~Reference~Device~Driver.\\
	Expected poor performance.
\paragraph{Windows~Advanced~Rasterization~Platform~(CPU)}
	The emulated execution of a \textit{DirectCompute}-kernel using a special software rasterizer devised by Microsoft in their latest revision of the \textit{DirectX}-framework.\\	
	Expectations unclear, but expected to perform better than standard software rasterization.\footnote{Insert reference to microsoft warp-msdn-page and explain what WARP promises and stuff about optimization for gpus.}\\

\noindent
These three \textit{DirectX} driver-types make out the subjects of this study.

\subsection{Kernels}
\label{sec:contribution:kernels}
In addition to the subject drivers mentioned in Section~\ref{sec:contribution:subjectofstudy}, two kernels with varying lavel of optimization have been examined\footnote{Why?}. These kernels are presented below.
\paragraph{Matrix~mult.~w.~Blocks}
	A kernel producing $AB=C$ from two given matrices, writing back $C$ for further analysis.\\
	The kernel is executed with one thread for each element in the square matrices, and likewize produce a lone element of the resulting matrix thread-wize.\\
	Execution is performed in blocks of $16x16$ threads, as this number was found to be the block dimension performing optimally whilst hardware~accelerated on the \textit{GPU}\footnote{Make sure of this!}. 
\paragraph{Matrix~mult.~w.~Blocks~\&~Shared~Memory}
	Likewize as with the previous kernel, but further optimized to utilize \textit{shared~memory} in order to reduce time-consuming reading of \textit{global~memory}\cite[p.~77-93]{Kirk:2010:PMP:1841511}.\\
	This kernel is presented as a test-case due to the preconditions of \textit{WARP} - stating that a kernel optimized for \textit{GPU}-execution is likewize optimized for execution with \textit{WARP}. Hence, we investigate a more optimized kernel to see whether or not this behaviour may be replicated in the experiment.\\

\noindent
Furthermore, aforementioned kernels both support integer- and floating-point precision.\\
These kernels are attached in their entirety under Appendix.

% CONTRIBUTION - TECHNOLOGIES
\subsection{Technologies}
\label{sec:contribution:technologies}
\subsubsection{Tools}
\label{sec:contribution:technologies}
The experiment process has been subdivided into three major components, all of which use Microsoft~\textit{Visual~Studio~2012} for compilation. These are presented below.

\paragraph{matrixgen}
Denotes a utility developed to generate matrices of different dimensions and data-types. Furthermore, \textit{matrixgen} compiles the reference matrix $Ref$ used when comparing the result returned from \textit{DirectCompute}. \\
\textit{matrixgen} is written in \texttt{C++} and utilizes \texttt{C++~AMP} to generate and multiply matrices $A$~\&~$B$ into product matrix $Ref$. In order to achieve random values in a \texttt{C++~AMP}-kernel the solution includes the random number generator-library \texttt{C++~AMP~RNG}.\\
As \textit{matrixgen} utilizes Microsoft~\texttt{C++~AMP}-technology, \textit{Windows~7} or later is required.

\paragraph{experiment}
Making out the primary component of the study, \textit{experiment} uses \textit{DirectCompute} to compile the product matrix $C$ from the matrices generated by \textit{matrixgen}. The application outputs data surrounding the execution of said kernel, such as it's execution time in milliseconds, to an intermediate file.\\
\textit{experiment} is written in \texttt{C++} with its respective \textit{DirectCompute}-kernels written in \texttt{HLSL}-syntax.\\
As \textit{experiment} is developed using the \textit{Windows~8~SDK}, \textit{Windows~8.0} is required. Furthermore, \textit{experiment} requires a \textit{DirectX~11.0}- or \textit{DirectX~11.1}-compatible graphics card.

\paragraph{analytics}
\textit{analytics} is a smaller utility developed to compose data surrounding possible precisional deviations in-between matrices $C$ and $Ref$. \textit{analytics} compiles the minimum- and maximum-deviation encountered, as well as to calculate the standard deviation of said precisional deviation. In turn, \textit{analytics} outputs this information to an intermediate file.\\
\textit{analytics} is written in \texttt{C++}.\\
\\
\noindent
These three applications are, in turn, run as subprocesses in a script specifying the various configurations and number of times to run each program. This script, written in \textit{Python}, then compiles the assorted results of these applications and outputs a range of files suitably formatted for interpretation by \textit{Gnuplot}.\\
More information surrounding how to run these programs can be found via the source repository (see Acknowledgments).

\subsubsection{Equipment}
\label{sec:contribution:equipment}
The results presented in this study is gathered from experiments performed on a system with the following specifications:
\begin{description*}
	\item[CPU]	Intel Q9550 Quad Core 2.83GHz
	\item[GPU]	ATI Radeon HD 5800
	\item[OS]	Windows 8.0
\end{description*}

% CONTRIBUTION - RESULTS
\subsection{Results}
\label{sec:contribution:results}
Preliminary results indicate a surprisingly well-performing WARP, roughly only doubling the execution time in regards to the same kernel hardware accelerated. Each configuration has been has been run using the same integer-precision 200x200-matrix. To gather the results presented below, each scenario has been run 100 times each. Please observe that these are preliminary tests, and more data is to be gathered before the closing of this article. \\
The results gathered during preliminary testing are presented below:
\begin{center}
	\begin{tabular}{| l | l | l | l |}
	\hline
	Acceleration & Min (ms) & Max (ms) & Average (ms)	\\ \hline
	Hardware & 25.86  & 43.12  & 26.41			\\ \hline
	Software & 16141.6 & 16906.7 & 16390.6		\\ \hline
	WARP & 46.18 & 64.25 & 48.47				\\
	\hline
	\end{tabular}
\end{center}

% From these kernels, data entailing the execution time of said kernel may be retrieved - which will make out the main subject~of~study throughout this material. Additional data retrieved from the execution concerning the experiment make out precision deviations in resulting matrix \textit{C} compared to the expected result \textit{Ref}.\\

% Contribution
%	Vilka empiriska resultat erhölls vid experimentdesignens implementation?
% Conclusion
% ...for each segment brought up under Contribution.

% CONCLUSION
\section{Conclusion}
\label{sec:conclusion}
Conclusion left out in regards to further development and analysis.
% Summary
%	Vilken bakgrund, utmaning, ansats och resultat omfattar studien?
% Discussion
%	Vilka relaterade studier förhåller sig materialet till?
%	Vilka tvetydliga aspekter av studien kräver diskussion?
% Answer and Oppertunity
%	Vilka fortsatta studier föreslår rapportens författare?

% CONCLUSION - FUTURE WORK
\subsection{Future~Work}
\label{sec:conclusion:futurework}
% Investigate double precision as to establish probable precision loss in terms of Microsoft WARP.

% ACKNOWLEDGMENTS
\section*{Acknowledgments} % The \section*{} command stops section numbering
\addcontentsline{toc}{section}{\hspace*{-\tocsep}Acknowledgments} % Adds this section to the table of contents with negative horizontal space equal to the indent for the numbered sections
\label{sec:acknowledgments}
I wish to express my gratitude to my fellow students, colleagues and close friends Bob, Benny and no-one for their work, co-operation and positive attitude throughout the execution of this experiment. \\
\\
The source code used during this study is freely available on \textit{GitHub}\footnote{\textit{GitHub}~Repository:~\url{http://bit.ly/1c4wd20}.}, along with a guide on how to compile and run the solution in order to replicate the experiment.

\section*{Appendix}
\addcontentsline{toc}{section}{\hspace*{-\tocsep}Acknowledgments} % Adds this section to the table of contents with negative horizontal space equal to the indent for the numbered sections
\label{sec:appendix}
% Pseudocode, or source code, or DirectCompute-kernels
\subsection*{Matrix~mult.~w.~Blocks}
\begin{lstlisting}
#ifndef DV2549_FXS_MULTFLOATBASIC_FX
#define DV2549_FXS_MULTFLOATBASIC_FX

#include <CommonFloat.fx>

[ numthreads( BLOCK_SIZE, BLOCK_SIZE, 1 ) ]
void main(
	uint3 tIdx : SV_GroupThreadID,
	uint3 bIdx : SV_GroupID ) {
	const uint row = bIdx.y * BLOCK_SIZE + tIdx.y;
	const uint col = bIdx.x * BLOCK_SIZE + tIdx.x;
	if( row >= cRows || col >= cCols ) {
		return;
	}
        
	float sum = 0;
	for( uint i = 0; i < aRows; i++ ) {
		uint idxA = row * aRows + i;
		uint idxB = col + bRows * i;
		sum += mA[ idxA ] * mB[ idxB ];
	}
	mC[ row * cRows + col ] = sum;
}

#endif // DV2549_FXS_MULTFLOATBASIC_FX
\end{lstlisting}

\subsection*{Matrix~mult.~w.~Blocks~\&~Shared~Memory}
\begin{lstlisting}
#ifndef DV2549_FXS_MULTFLOATTILE_H
#define DV2549_FXS_MULTFLOATTILE_H

#include <CommonFloat.fx>

groupshared float mAs[ BLOCK_SIZE ][ BLOCK_SIZE ];
groupshared float mBs[ BLOCK_SIZE ][ BLOCK_SIZE ];

[ numthreads( BLOCK_SIZE, BLOCK_SIZE, 1 ) ]
void main(
	uint3 tIdx : SV_GroupThreadID,
	uint3 bIdx : SV_GroupID ) {
	const uint row = bIdx.y * BLOCK_SIZE + tIdx.y;
	const uint col = bIdx.x * BLOCK_SIZE + tIdx.x;
	
	float sum = 0;
	const uint blocks = ceil( 
		(float)aRows / (float)BLOCK_SIZE );
	for( uint i = 0; i < blocks; i++ ) {
		mAs[ tIdx.y ][ tIdx.x ] = mA[ 
			row * aRows + ( i * BLOCK_SIZE + tIdx.x ) ];
		mBs[ tIdx.y ][ tIdx.x ] = mB[ 
			col + bRows * ( i * BLOCK_SIZE + tIdx.y ) ];
		GroupMemoryBarrierWithGroupSync();
        
		for( uint j = 0; j < BLOCK_SIZE; j++ ) {
			sum += 
				mAs[ tIdx.y ][ j ] * mBs[ j ][ tIdx.x ];
		}
		GroupMemoryBarrierWithGroupSync();
	}
	if( row >= cRows || col >= cCols ) {
		return;
	}
	mC[ row * cRows + col ] = sum;
}

#endif // DV2549_FXS_MULTFLOATTILE_H

\end{lstlisting}

\bibliographystyle{IEEEtranS}
\bibliography{article}
\end{document}

% To-be-inserted references and/or footnotes:
% Microsoft Warp: http://msdn.microsoft.com/en-us/library/windows/desktop/gg615082%28v=vs.85%29.aspx